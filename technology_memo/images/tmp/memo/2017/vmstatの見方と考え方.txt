vmstatの見方と考え方

1.基本的な使い方

オプション無しで実行すると、以下のように現時点でのパフォーマンス情報が出力される。
vmstat

[root@test-centos7 ~]# vmstat
procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu-----
 r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st
 1  0      0  80556    128 1391560    0    0     5     6    9    2  0  0 100  0  0
※見方は後述

2.○秒ごとに定期実行させる
引数として間隔(秒単位)を指定することで、その間隔ごとにパフォーマンス情報を出力させることができる。
-------------------------------
vmstat 実行間隔(秒)
-------------------------------

この実行間隔を指定してコマンドを実行すると、出力結果にヘッダーが定期的（コマンド実行時のウィンドウサイズによって行数が変動する）に挟まれてしまう。
邪魔であれば、「-n」オプションを付与することでヘッダーを最初の1回(実行時に最初に挿入される分)のみに抑える事ができる。
-------------------------------
vmstat -n 実行回数
-------------------------------

なお、実行回数の後ろに更に数字を引数として与える事で、実行回数も指定することができる。
-------------------------------
vmstat 実行間隔(秒) 実行回数
-------------------------------

3.メモリキャッシュのアクティブ/非アクティブ領域の内訳を確認する
「-a」オプションを付与することで、メモリキャッシュのアクティブ(利用中で、開放できない領域)/非アクティブ(最後に利用されてから一定時間が経過したため、すぐに廃棄できる領域)の内訳を確認することができる。
-------------------------------
vmstat -a
-------------------------------

[root@test-centos7 ~]# vmstat
procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu-----
 r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st
 1  0      0  95740    128 1365428    0    0     4     6    9    4  0  0 100  0  0
[root@test-centos7 ~]#
[root@test-centos7 ~]# vmstat -a
procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu-----
 r  b   swpd   free  inact active   si   so    bi    bo   in   cs us sy id wa st
 1  0      0  95720 1273136 372676    0    0     4     6    9    4  0  0 100  0  0
比べて見るとわかるが、オプション無しとくらべて「buff」「cache」がなくなり、「inact」「active」がかわりに表示されている。" inact … 非アクティブ(最後に利用されてから一定時間が経過したため、内容をすぐに廃棄できる)な状態のメモリキャッシュの容量
" active … アクティブ(何らかの形でシステムで利用中のため、開放できない)な状態のメモリキャッシュの容量
activeのメモリはすぐには利用できないので、free + inactの値が利用可能なメモリ容量だと考えるといいだろう。

4.パフォーマンス情報にタイムスタンプを付与する
「-t」オプションを付与することで、出力されるパフォーマンス情報にタイムスタンプを付与することができる。
-------------------------------
vmstat -t
-------------------------------
[root@test-centos7 ~]# vmstat 1 -t
procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu----- -----timestamp-----
 r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st                 JST
 1  0      0  95740    128 1365432    0    0     4     6    9    4  0  0 100  0  0 2015-07-20 10:19:15
 0  0      0  95732    128 1365432    0    0     0     0   66  115  0  0 100  0  0 2015-07-20 10:19:16
 0  0      0  95732    128 1365432    0    0     0     0   54   95  0  0 100  0  0 2015-07-20 10:19:17
 0  0      0  95732    128 1365432    0    0     0     0   72  127  0  0 100  0  0 2015-07-20 10:19:18
 0  0      0  95572    128 1365432    0    0     0     0  117  192  0  0 99  0  0 2015-07-20 10:19:19
 0  0      0  95572    128 1365432    0    0     0     0   60  100  0  0 100  0  0 2015-07-20 10:19:20
 0  0      0  95608    128 1365432    0    0     0     0   58  107  0  0 100  0  0 2015-07-20 10:19:21
 0  0      0  95608    128 1365432    0    0     0     0   57  104  0  0 100  0  0 2015-07-20 10:19:22
 0  0      0  95608    128 1365432    0    0     0     0   62  107  0  0 100  0  0 2015-07-20 10:19:23
 0  0      0  95608    128 1365432    0    0     0     0   61  108  0  0 100  0  0 2015-07-20 10:19:24
 0  0      0  95608    128 1365432    0    0     0     0   53   95  0  0 100  0  0 2015-07-20 10:19:25

5.表示される容量の単位を切り替える
通常、vmstatで表示される容量の単位はKB(キロバイト)となっているのだが、「-S」オプションでk(キロバイト)、m(メガバイト)を切り替える事もできる。
-------------------------------
vmstat -S (k or m)
-------------------------------
[root@test-centos7 ~]# # キロバイト
[root@test-centos7 ~]# vmstat -S k
procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu-----
 r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st
 1  0      0  98250    131 1398202    0    0     4     6    9    4  0  0 100  0  0
[root@test-centos7 ~]#
[root@test-centos7 ~]# # メガバイト
[root@test-centos7 ~]# vmstat -S m
procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu-----
 r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st
 1  0      0     98      0   1398    0    0     4     6    9    4  0  0 100  0  0

6.各種カウンターの統計情報を出力する
「-s」オプションを付与すると、各種情報をその詳細な名称とともにリスト形式で出力させることができる。
-------------------------------
vmstat -s
-------------------------------
[root@test-centos7 ~]# vmstat -s
      1885468 K total memory
      1789744 K used memory
       372696 K active memory
      1273132 K inactive memory
        95724 K free memory
          128 K buffer memory
      1365432 K swap cache
      2113532 K total swap
            0 K used swap
      2113532 K free swap
        76349 non-nice user cpu ticks
          282 nice user cpu ticks
        71973 system cpu ticks
    379256851 idle cpu ticks
        31778 IO-wait cpu ticks
            7 IRQ cpu ticks
         4073 softirq cpu ticks
            0 stolen cpu ticks
     17023816 pages paged in
     21544483 pages paged out
            0 pages swapped in
            0 pages swapped out
     78935690 interrupts
    143253821 CPU context switches
   1435457229 boot time
        61294 forks

7.slabの使用状況を確認する
「-m」オプションを使用することで、メモリのslabの(slabinfo)情報について出力させることができる。
-------------------------------
vmstat -m
-------------------------------
[root@test-centos7 ~]# vmstat -m -n
Cache                       Num  Total   Size  Pages
ccid2_hc_tx_sock              0      0   1280     12
scsi_cmd_cache              324    324    448     18
kcopyd_job                    0      0   3312      9
dm_uevent                     0      0   2608     12
dm_rq_target_io               0      0    424     19
UDPLITEv6                     0      0   1152     14
UDPv6                        28     28   1152     14
tw_sock_TCPv6                32     32    256     16
TCPv6                        48     48   2048     16
cfq_queue                   374    442    232     17
bsg_cmd                       0      0    312     13
mqueue_inode_cache           18     18    896     18
hugetlbfs_inode_cache        26     26    608     13
configfs_dir_cache           92     92     88     46

8.デバイス・パーティションの統計情報を出力させる
vmstatでは、「-d」オプションでデバイスごとの統計情報を出力させることができる。
-------------------------------
vmstat -d
-------------------------------

[root@test-centos7 ~]# vmstat -d
disk- ------------reads------------ ------------writes----------- -----IO------
       total merged sectors      ms  total merged sectors      ms    cur    sec
fd0        2      0      16      85      0      0       0       0      0      0
sda   103345    837 34047617 1035927 500440  22513 43093959 6204752      0    862
sr0        0      0       0       0      0      0       0       0      0      0
dm-0     246      0    1968     721      0      0       0       0      0      0
dm-1  102522      0 34001881 1039381 521883      0 43089569 7236979      0    864

それぞれの項目の意味を、以下に記述する。
●reads/writes
" total … 読み込み/書き込みに成功した総数
" merged … グループ化した読み込み/書き込みの数
" sectors … 読み込み/書き込みに成功したセクタ数
" ms … 読み込み/書き込みに使用した時間(ミリ秒)
この項目の値は起動時からの計測なので、リアルタイムでの性能計測には不向きなので注意。

IO
" cur … 実行中のIO
" s … IOに使用した時間(秒)

残念ながら各デバイスごとに出力を絞る機能はついていないため、必要であればgrepと組み合わせると良いだろう。
-------------------------------
vmstat -nd 実行間隔(秒) | grep -e ^disk- -e デバイス
-------------------------------

なお、「-D」オプションを使用することで、全てのデバイスを統計してのステータスを表示させることもできる。
-------------------------------
vmstat -D
-------------------------------
[root@test-centos7 ~]# vmstat -D
            5 disks
            2 partitions
       206117 total reads
          837 merged reads
     68051546 read sectors
      2076216 milli reading
      1030952 writes
        22626 merged writes
     86263314 written sectors
     13458654 milli writing
            0 inprogress IO
         1730 milli spent IO

パーティションごとのIO値を取得する場合は、「-p」オプションを用いる。
-------------------------------
vmstat -p 対象パーティション(デバイスファイル)
-------------------------------
[root@test-centos7 ~]# vmstat -p /dev/sda2
sda2          reads   read sectors  writes    requested writes
              101975   34004905     503730   43130448
[root@test-centos7 ~]# vmstat -p /dev/sda2 1
sda2          reads   read sectors  writes    requested writes
              101975   34004905     503730   43130448
              101975   34004905     503735   43130494
              101975   34004905     503735   43130494
              101975   34004905     503735   43130494
              101975   34004905     503735   43130494
              101975   34004905     503735   43130494
              101975   34004905     503735   43130494
              101975   34004905     503735   43130494
              101975   34004905     503735   43130494
              101975   34004905     503735   43130494

それぞれの項目の意味は以下。
" 指定したパーティションからの読み込み数
" 指定したパーティションから読み出されたセクターの数
" 指定したパーティションへの書き込み数
" 指定したパーティションへの書き込み要求数

9.横に広く表示させる
パフォーマンス情報を出力させる際、ちょっと見にくいなと思ったら、「-w」オプションで横に広く表示させる事ができる。
-------------------------------
vmstat -w
-------------------------------
[root@test-centos7 ~]# vmstat
procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu-----
 r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st
 1  0      0  96364    128 1365472    0    0     4     6   10    4  0  0 100  0  0
[root@test-centos7 ~]#
[root@test-centos7 ~]# vmstat -w
procs -----------------------memory---------------------- ---swap-- -----io---- -system-- --------cpu--------
 r  b         swpd         free         buff        cache   si   so    bi    bo   in   cs  us  sy  id  wa  st
 1  0            0        96364          128      1365472    0    0     4     6   10    4   0   0 100   0   0

なにもここで説明しなくてもvmstatの説明なんてそこらじゅうにある訳ですが、同じコマンドでもカーネルのバージョンとかディストリビューションとかで結構違ってくるので、ここではCentOS5.2でのvmstatについて記載しておくことに。

 　vmstatを実行すると…

[root@chihiro ~]# vmstat 5
procs -----------memory---------- ---swap-- -----io---- --system-- -----cpu------
 r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st
 0  0    136  10836   3744 1940256    0    0   174  2050  128   96  1  6 74 19  0
 0  0    136  10456   3720 1940424    0    0     0  6731 6067 7326  0  4 85 11  0
 0  0    136  10028   3700 1940796    0    0     0  6730 6039 7285  0  5 84 11  0


　こんな感じでレポートがズラズラと出力されてきます。
 　一番注目されやすい項目としては、末尾にある「cpu」の項目たち。ここは「その時間のうちにどれくらいの割合、CPUを使ったか」というレポートになっています。順番が違いますがこんな意味合いを持ちます。（説明しやすいので並び替えました）
 　　sy　…　カーネルコード（OS自身、またLinuxシステムコール等を呼び出された等）の処理のために費やした時間の割合
 　　us　…　カーネルコード以外の処理に費やした時間の割合。要するに、一般のプログラムが動いていた時間の割合
 　　wa　…　データの入出力処理（ディスクへのアクセス、ネットワークへのアクセス）を試みたものの、結果的にデータを待っていた時間の割合
 　　id　…　アイドル時間の割合。要するに「ぼけー」っとしていた時間のこと。


 　とかく、ロードアベレージとか、アイドル時間の大小ばかりに目がいきがちですが、それでシステム全体のパフォーマンスをはかるのは早計です。考慮すべき点は他にもあります。

 　サーバの利用者から見たとき、そのサーバが「重い」と感じているかどうか、もっと端的に読み取れる項目があります。それはvmstatの最初の項目「procs」です。

 　procsの項目：
 　　r　…　実行可能で、「実行キュー」に入っているプロセスの数。
 　　b　…　本来は実行可能なプロセスであるが、何らかの理由で処理を「ブロック」されているプロセスの数

 　まず、「実行キュー」とは何かといいますと、Linuxは「時分割」という手法で、複数のプロセスがさも同時に動いているかのように見せる方法を採っています。プログラムA・B・Cと3個あったとして、プロセッサが1個しか無いなら、本当は同時には1個のプログラムしか実行できないはずです。そこで、1個のプログラムがプロセッサを占有する時間をごく短くして、プログラムA→プログラムB→プログラムCと、順番にかわりばんこに処理すると、あたかも3個のプログラムが同時に動作しているように見えるじゃありませんか。
 　で、このプログラムの切り替えのために、「実行キュー」という仕組みが用意されていて、駅の券売機か銀行のATMの待ち行列みたく、これから実行してもらえるプログラムが並んで待っている状態を作ります。全てが順調に処理されているなら、通常はこの「実行キュー」に入ったプログラムはほとんど即時に処理されてキューから退出するのですが、CPUが忙しかったりプログラムの実装がアレだったりすると、この「実行キュー」にはいったまま待たされるという状態が生じます。
 　実行キューに入ったプログラムは、本当なら実行してもらえたはず（CPUを占有させてもらえたはず）なのに順番が回ってこなかったということになりますので、そのプログラムを使っている人からみると、プログラム（サーバ）からの返事がない（返事が遅い・返事がスムーズでない…）ということを体感してしまうかもしれません。
 　以上のことから、procsのrの項目がいつも0じゃない状態が続いているようなら、利用者は「このサーバ、遅いな！」と感じている可能性があります。

 　また、本来は実行可能なプロセスであるが、何らかの理由で処理を「ブロック」されているプロセスとは何のことでしょうか。これは、ほとんどの場合は、ディスクやネットワークへの入出力を待っている状態に置かれているプロセスです。しかも、入出力を待っていたら次の自分の順番が回って来ちゃったというようなケースです。
 　CPUの挙動に比べたら、ディスクやネットワークへのアクセスというものはもの凄く遅い物です。大きなデータを読んだり書いたり、あるいはいくつものプロセスが同時に読んだり書いたりすれば、それだけアクセス速度は落ちます。そのような状態の時にこの値が大きくなることがあります。
 　このような場合も、結果的にプログラムの実行が止まっていることになるので、プログラム（サーバ）の利用者からしたらプログラム（サーバ）からの返事がない（返事が遅い・返事がスムーズでない…）ということを体感してしまうかもしれません。

 　サーバのアイドル時間と、プロセスの実行状態とは関連することも多いですが、プログラムの実装次第ではアイドル時間はやたらあるのにサーバが遅いと言われるということもままあります。



 　他の項目については、メモリやスワップに関する情報、ブロックデバイスへの入出力頻度等が注目されます。

 　memoryの項目：
 　　swpd　：　使用しているスワップ領域の量。どんなにメモリが空いていても、ここの数値が一定の量に達していることがあります。まあ、増減が無ければ（後述する、siやsoの値が0のままなら）それほど深刻に考える必要性は薄いでしょう。
 　　free　：　純粋に未使用状態なメモリの量。メモリを潤沢に搭載していて、大きなプログラムが動作しているわけでもないのに、この値がもの凄く小さくなっている事があります。その場合は、以下のbuffとcacheの値（特にcacheの方）を見てください。
 　　buff　：　主にカーネルがバッファ領域として使用しているメモリ量。それほど大きくなることは無いけども、メモリ全体が逼迫してくるとここの領域を削ってどうにかしようとがんばるようになります。
 　　cache　：　ディスクアクセス時にキャッシュデータを保存しているメモリの量。しばらくするとここの値がべらぼうに大きくなるのが一般的です。しかしそれに目くじらを立てる必要はありません。なぜなら、この領域は未使用状態なメモリと同じ扱いだからです。空いてる領域を未使用のままにしておくのはもったいないので、過去のディスクアクセスの際に読んだり書いたりしたデータを保存しておこう…ということに使っているからです。この項目に代表されるキャッシュデータは別に無くなっても深刻じゃない（またあとでディスクから読み出せば良いだけ）ので、メモリを沢山必要になったときにはキャッシュデータを捨ててメモリをプログラムのために割り当てることになります。

 　swapの項目：
 　　si　：　スワップ領域から読み込んでメモリに展開したデータの量（スワップ・イン）
 　　so　：　メモリからスワップ領域に書き込んだデータの量（スワップ・アウト）

 　メモリがいよいよ不足してくると、メモリ上にある不要不急のデータやプログラムをディスクに逃がしてメモリを空けようとがんばります。そして、そのデータやプログラムが必要になったら今度はディスクからメモリの上に戻してプログラムを実行したりデータをいじったりします。その挙動がここに現れます。
 　si、so共に常時ゼロという状態が基本です。ここに常時数値が現れることは、そのサーバにはメモリが足りないか、メモリをバカ食いするプログラムが多すぎるかのどちらかということになります。

 　ioの項目：
 　　bi　：　ブロックデバイス（主にディスク等）からの読み取り量
 　　bo　：　ブロックデバイス（同上）への書き込み量

 　複数のブロックデバイスがあっても、ここではその合計値しか表示されません。

 　systemの項目：
 　　in　：　割り込み処理の回数
 　　cs　：　コンテクストスイッチの回数

 　「割り込み処理」とは、人間の生活でいえば玄関のチャイムとか電話の呼び出しとかキッチンタイマーのベルとかトイレに籠城している父ちゃんの「紙もってこ～い」とかそういった類に似ています。それまでやっていたことを一時的に止めて玄関のインターフォン越しに相手を確認したり、電話に出たり、鍋の状態をみたりしますよね？これをCPUもやっていて、その処理全般のことを「割り込み処理」と言っています。その回数をレポートしています。

 　「コンテクストスイッチ」とは、主にプログラムの実行を切り替えることを言います。プログラムの切り替えは、主に
　　・そのプログラムが一度に占有できる時間を使い切った
　　・カーネルに時間の掛かる処理（例えばディスクアクセス）を依頼した
　　・割り込み処理が発生した
　　・プログラムが「自主的に」処理時間を返上した
　　・そもそもプログラムが終わった
　等のタイミングで発生します。なお、この「コンテクストスイッチ」という処理（つまり動作するプロセスを切り替える処理）には一定のロスが生じてしまいます。（これを「オーバーヘッド」と呼んだりします）プログラムを切り替えるためには、そのプログラムが次に実行できるために必要な情報を漏らさず保存しておかなければならず、次に実行する別のプログラムが必要とする情報を漏らさず復元しなければなりません。このような処理は頻発すればするほど、本来のプログラムの実行に使える時間が短くなることを意味します。

 　まあ、この2個の項目を見て直ちになんらかのクリティカルな状態にあるかとかそういう判断をすることはまずマレです。ただ、特徴的なくらい飛び抜けて多いとか少ないとか読み取れる場合には、何らかの異常・ボトルネックが生じているかもしれないと判断をするトリガーにはなるかもしれません。


 　さて。cpuのidがとても低い状態が悪いことでしょうか？
 　確かに、負荷が原因で障害が発生する場合、idが0かもの凄く低い状態であることが多い傾向にあることは事実です。しかし、ここだけを見てサーバに問題があると判断するのは問題があります。
 　逆に、idが高いのに重い重いと言われるケースもありえます。

 　また、usが高いとか、syが高いとかいうケースも、それが「良い（妥当）」か「悪い」のか、サーバの用途によって判断が分かれる事にも注意が必要です。

 　例えば。
 　NFSサーバとか、sambaサーバとかといった用途で使用していて、ファイルアクセスが頻繁なら、syが高くなりがちなのは妥当でしょう。一方で、perlとかphpとかのスクリプト言語、C言語で主に純粋な計算量が多いプログラムを利用しているというようなケースなら、usが高くなることは妥当だと判断することになるでしょう。
 　また、cron等でバッチ処理が多く動作するサーバなら、ぶっちゃけprocsの実行キュー待ちプロセス数やブロックされたプロセス数が増加していてもあまり気にする必要性は高くないと判断することもできます。一方で、Webサーバ等の用途なら、実行キュー待ちのプロセス数が多くなってくると、利用者からは「重い」と目の敵にされるかもしれません。
 　swapについては基本的にはsiとsoは0で有り続けることを至上命題にすべきです。ただ、一時的に目をつむるケースも出てくるかもしれません。例えばデータのバックアップとかファイルの整理などで一時的に大きなプログラムを動かさなければならない時とか。さらにその時間はアクセスが無くて他の人に迷惑をかけないなら、どれだけスワップしようがまあ我慢できる範囲内なら、まあいっか…というような判断もありえます。

 　このように、そもそもそのサーバはどんな使い方をしているのかということに着目しつつ、負荷の状態をチェックするべきです。さもなければサーバ管理者とお金がいくらあっても足りないことになりますからね。（笑） 


#---------------------------------------------------------------------------------------
●rが高く、CPU使用率も高い場合

procs -----------memory----------    ---swap-- -----io---- --system-- -----cpu------
 r  b   swpd   free   buff  cache     si   so    bi    bo   in   cs   us  sy  id  wa
 5  10  5168   51332  82040 1815280   0    0    2430  201  998   3211 12   2  56  30
 3  12  5168   50552  82044 1811968   0    0    6150  183  1623  2312 22   3  54  21
 3  16  5168   49708  82032 1812704   0    0    7312  103  1364  1127  5   1  75  20
 2  14  5168   49432  82056 1812944   0    0    4492  302  2031  3819 12   3  74  11

r の数値が高いのは、CPUの処理待ちが多いといった状態です。
 明らかにCPUに負荷がかかっているので、CPUのクロック数を上げたり、CPUの数を増やせばそれなりに改善していきます。
ただ、CPUに待ちが生じるのはハードウェア的な処理速度云々より、CPUを効率よく使わないOSやアプリケーションの問題が多いため、まずはソフトウェ ア側から見直すのが先決でしょう。最初からCPUにやさしい設計をしてこなかった場合、ソフトウェアの見直しでかなり劇的に改善されることが多いようです。

 上記の例は、データベースのトリガーにロックがかかり、ディスクI/Oまで遅延が発生してしまった例です。
 
 CPUの数を増やして負荷を下げるのも方法ですが、CPUの数を増しても負荷の高いアプリケーションを動かしたりすると、あまり効果はありません。CPUの数を増すのは並列処理にのみ効果があるので、同時に動作するプロセスが多い場合に検討すればよいと思います。

#---------------------------------------------------------------------------------------
●si so が高い場合

procs -----------memory----------    ---swap-- -----io---- --system-- -----cpu------
 r  b   swpd   free   buff  cache     si   so    bi    bo   in    cs   us  sy  id  wa
 0  1   49708  51332  82040 1815280     0  2992  381  256   347   623   4   2  56  38
 1  1   49708  50552  82044 1811968  1132   365 1382   81   323   461  12   3  64  21
 0  0   49708  49708  82032 1812704  1225    32 5834  321   429  1127   5   1  76  29
 2  1   49708  49432  82056 1812944   321   700 4520  250   212  1229   4   1  76  20
 
これは単に搭載しているメモリの不足です。
アプリケーションを見直したり、バッチの実行時間をずらしたりと運用で対処することは当然必要ですが、なによりメモリ増設を一番に考えたほうが良いでしょ う。SWAP領域はあくまで一時的な避難場所なので、使わないに越したことはありません。最近はメモリも安くなったので、メモリを惜しみなく追加しましょ う。(^^;　特にデータベースを使っている場合はなおさらです。

#---------------------------------------------------------------------------------------
●b のプロセスが多くCPU負荷が高い場合

procs -----------memory----------    ---swap-- -----io---- --system-- -----cpu------
 r  b   swpd   free   buff  cache     si   so    bi    bo   in    cs   us  sy  id  wa
 0  7   4956  51332  82040 1815280     0    0   10180  139   447 1342   4   2  86   8
 1  6   5168  50552  82044 1811968     0    0   24950   30   323  461   12  3  74  11
 0  5   5168  49708  82032 1812704     0    0    5834   10   829 1127   5   1  75  20
 0  4   5168  49432  82056 1812944     0    0    4520 4250   882 1229   4   1  74  22

b の数値が高いのは、I/O待ちをしているプロセスが多く存在するということになります。
 経験的な話ですが、b の値が5～7以上を超えている状態が長く続いたとすると、かなりI/Oディバイスに負荷がかかっていると言えるでしょう。
bi と bo の値も通常より上がっていれば、確実にディスクI/O速度が間に合っていないことになるので、RAIDやディスク回転数のアップなどを考えてもいいかもしれません。

ただ、同時にsi so が高い場合は、メモリが不足したためにSWAP領域を使ったことになり、この場合はメモリ容量をアップすることが先決です。 

#---------------------------------------------------------------------------------------

vmstatの右端の、「cpu」のところにある「id」でサーバの重い・軽いを判断してはいけないという理由がイマイチわからないのでもう少し説明して欲しいというリクエストを受けたので、説明を追加する。

 　まず、理由は複数あるのけども、その中で最も判りやすい例を示す。

 　ターミナルを2個開いて、片方でvmstatを、もう片方でtopコマンドを実行してみよう。すると…
[root@nfsserver ~]# vmstat 5
procs -----------memory---------- ---swap-- -----io---- --system-- -----cpu------
 r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st
 1  1      4  78100 465408 11877040    0    0   170    23    0    2  0  1 97  2  0
 2  1      4  79332 465592 11876136    0    0  4108   211 5870 3475  1  3 83 13  0
 0  1      4  77096 467276 11871576    0    0  5503   336 6187 4404  1  4 81 14  0
 0  1      4  80312 469152 11863716    0    0  3864    26 5157 2085  0  1 86 14  0
 0  1      4  77016 471196 11859260    0    0  4785    68 5458 4898  1  5 81 13  0
 1  1      4  79320 472012 11850980    0    0  5079  1895 6298 2508  0  1 85 13  0
 3  1      4  79104 474516 11845392    0    0  4951   754 6324 4816  1  4 81 14  0
 0  1      4  75820 477668 11834292    0    0  3651   201 5537 4384  1  4 80 15  0

　CPUの処理時間を見ると、%Idleは８０％以上あるように見える。NFSサーバなので、ディスクへのI/Oが処理の中心になるので、%wioが多いのは仕様である。
 　このような状態のサーバでも、たまに「重い」と言われることがある。

 　経験の浅いサーバ管理者だったら、「は？」とか思ってしまうかもしれない。
 　しかし、topコマンドで見ると一発で答えがわかる。
[root@nfsserver ~]# top

top - 14:07:00 up 32 days,  8:52,  1 user,  load average: 1.81, 1.68, 1.24
Tasks: 469 total,   1 running, 468 sleeping,   0 stopped,   0 zombie
Cpu0  :  0.0%us,  0.0%sy,  0.0%ni,100.0%id,  0.0%wa,  0.0%hi,  0.0%si,  0.0%st
Cpu1  :  0.0%us,  0.3%sy,  0.0%ni, 99.7%id,  0.0%wa,  0.0%hi,  0.0%si,  0.0%st
Cpu2  :  0.0%us,  0.0%sy,  0.0%ni,100.0%id,  0.0%wa,  0.0%hi,  0.0%si,  0.0%st
Cpu3  :  1.0%us,  5.0%sy,  0.0%ni,  0.0%id, 92.7%wa,  0.0%hi,  1.3%si,  0.0%st
Cpu4  :  0.0%us,  0.0%sy,  0.0%ni,100.0%id,  0.0%wa,  0.0%hi,  0.0%si,  0.0%st
Cpu5  :  0.3%us,  0.3%sy,  0.0%ni, 94.0%id,  4.0%wa,  0.3%hi,  1.0%si,  0.0%st
Cpu6  :  0.3%us,  0.7%sy,  0.0%ni, 97.4%id,  1.7%wa,  0.0%hi,  0.0%si,  0.0%st
Cpu7  :  0.0%us,  0.3%sy,  0.0%ni, 95.3%id,  2.7%wa,  0.0%hi,  1.7%si,  0.0%st
Mem:  14363332k total, 14286036k used,    77296k free,   508620k buffers
Swap: 14679832k total,        4k used, 14679828k free, 11667896k cached

  PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  COMMAND
29685 root      18   0  197m 124m  760 D    5  0.9   0:13.81 rsync
  463 root      10  -5     0    0    0 S    0  0.0  28:23.28 kswapd0
 4231 root      RT   0 88192 4328 2704 S    0  0.0  10:09.53 multipathd
27891 root      15   0     0    0    0 S    0  0.0   0:33.86 nfsd
28012 root      15   0     0    0    0 S    0  0.0   0:35.92 nfsd
28022 root      15   0     0    0    0 S    0  0.0   0:30.93 nfsd
28072 root      15   0     0    0    0 S    0  0.0   0:33.64 nfsd
29681 root      15   0 85124 3180 2464 S    0  0.0   0:00.98 sshd
32756 root      15   0 12976 1360  796 R    0  0.0   0:00.06 top
    1 root      18   0 10316  676  568 S    0  0.0   0:02.27 init
    2 root      RT   0     0    0    0 S    0  0.0   0:06.38 migration/0
    3 root      34  19     0    0    0 S    0  0.0   0:00.01 ksoftirqd/0


イマドキのサーバはマルチコア・マルチプロセッサが当たり前なので、コア毎の状態を見る必要がある。
 「Cpu3」の状態を見てもらいたい。ここだけ%waの数値が「92.7」とかなっていることが判るだろう。

 これは何をしているのかというと、このコアがこのサーバのI/Oの多くをほぼ独占している状態にあることを意味している。（完全に独占しているとは言えないが…）

 たとえ、CPUがマルチコア・マルチプロセッサ化されたとは言っても、I/Oはまだまだ単一の処理しか対応できないのが現実である。ディスクにしてもネットワークにしても、ある瞬間にそのディスクやネットワークを使用できるスレッドはたった一つであり、誰かがディスクアクセスを行っているその瞬間は他の人はディスクアクセスが終了するか使用する権利が回ってくるまで待機させられることとなる。

 vmstatやsarコマンドをそのまま眺めているだけでは、こうした事象には気がつきにくくなっている。なにしろvmstatやsarコマンド、topも標準のままでは全てのコア・CPUの平均値しかレポートしないので、こうしたI/Oネックによるサーバの「重さ」に管理者が気がつかないということになってしまっているのであった。

 その意味でも、vmstatの「cpu」よりも「procs」に注目するようにと、以前のアーティクルで記述したのであった。「procs」は「ブロックされたプロセスの数」を表示しているので、上記サンプルのように、１／８のコアだけが忙しくても、現実に実行をブロックされたプロセスが発生すればprocsの欄にレポートされるのである。

 なお、topコマンドで各コア・プロセッサごとの処理状態を見たい場合は「1」を押す。すると、全体のCPU平均と、コア・プロセッサ毎の表示が切り替わる。また、sarコマンドでコア・プロセッサ毎の処理状態を確認したい場合は「-P ALL」オプションを付ける。ALLのかわりにCPUのIDを指定すると、そのコア・プロセッサだけ表示される。ちなみに -P ALLをつけた場合はこんな感じ。
00時00分01秒       CPU     %user     %nice   %system   %iowait    %steal     %idle
00時20分01秒       all      0.88      0.00      4.12     17.46      0.00     77.54
00時20分01秒         0      0.05      0.00      0.15      0.05      0.00     99.76
00時20分01秒         1      0.05      0.00      0.62      0.02      0.00     99.31
00時20分01秒         2      0.71      0.00      1.55     70.52      0.00     27.23
00時20分01秒         3      0.45      0.00      2.70     36.00      0.00     60.86
00時20分01秒         4      1.44      0.00      4.13      0.07      0.00     94.35
00時20分01秒         5      1.24      0.00      7.41     12.05      0.00     79.30
00時20分01秒         6      1.54      0.00      5.86     11.18      0.00     81.42
00時20分01秒         7      1.59      0.00     10.52      9.81      0.00     78.08


この時間だと、cpu2がせっせとIO処理をしている（cpu3も結構がんばっている）が、全体としては17.46%にしか見えないので、「ま、まだ楽勝じゃん！？」とか思われてしまうこともしばしば。

 これが、「%Idle」の多い少ないだけでサーバの「重い」「軽い」を判断してはいけない理由の一つ。
 

#---------------------------------------------------------------------------------------
パフォーマンスに関して注目すべき項目の簡単なフロー
#---------------------------------------------------------------------------------------
1.システム全体の調査

┌───┐
│vmstat│
└───┘
    ↓
 ※1↓
┌───┐Yes   ┌────────┐
│ld<10 │───│CPU使用率の評価 │
└───┘      └────────┘
    ↓No
 ※2↓
┌───┐No    ┌───────────┐
│so>10 │───│ディスク使用率の評価  │
└───┘      └───────────┘
    ↓Yes
    ↓
┌─────┐
│メモリ不足│
└─────┘

※1.CPUのアイドル状況をチェック
※2.スワップアウトをチェック
#---------------------------------------------------------------------------------------
2.CPU使用率の調査

┌───┐
│vmstat│
└───┘
    ↓
 ※1↓
┌───┐Yes   
│sy>30 │────────┐
└───┘                ↓
    ↓No               ※3↓
    ↓               ┌───┐No    ┌───────────┐
    ↓               │in>200│───│ディスク使用率の評価  │
    ↓               └───┘      └───────────┘
    ↓                   ↓Yes
    ↓                   ↓
    ↓               ┌─────────┐
    ↓               │ハードウェアの問題│
    ↓               └─────────┘
    ↓
 ※2↓
┌───┐Yes   ┌─────┐
│r>0   │───│CPUの追加 │
└───┘      └─────┘
    ↓No
    ↓
┌──────────┐
│CPUのアップグレード │
└──────────┘

※1.システムCPUの使用率のチェック
※2.実行待ちプロセスのチェック
※3.デバイスの過度な割り込みチェック
#---------------------------------------------------------------------------------------
3.ディスク使用率の調査

┌───┐
│lostat│
└───┘
    ↓
 ※1↓
┌────┐Yes   ┌──────────┐
│%utl>80 │───│デバイスの負荷分散  │
└────┘      └──────────┘
    ↓No
 ※2↓
┌────┐Yes   ┌──────────────┐
│w/s>r/s │───│ディスク・キャッシュの使用  │
└────┘      └──────────────┘
    ↓No
    ↓
┌─────────┐
│ネットワークの調査│
└─────────┘

※1.ディスク使用率が過度に高いデバイスのチェック
※2.書き込み要求の比率のチェック
#---------------------------------------------------------------------------------------
vmstatから見る性能の判断基準
#---------------------------------------------------------------------------------------
●CPU
CPUの負荷状況は、vmstatのr値から大体分かります。r値は、「実行可能キュー」な訳ですから、値が大きければそれだけ処理待ちのジョブが溜まっちゃってるということで、CPUのパワー不足であることが読みとれます。 で、ある本に書かれていたは、以下通りになっています。キューをシステムのCPU数で割った値で判断します。
┌───────┬─────────┐
│r/cpu         │ 状態             │
├───────┼─────────┤
│r/cpu = 0     │CPUアイドル状態   │
├───────┼─────────┤
│0< r/cpu <3   │問題なし          │
├───────┼─────────┤
│3< r/cpu <5   │CPU過負荷         │
├───────┼─────────┤
│r/cpu > 5     │CPU過負荷(危険値) │
└───────┴─────────┘

●swap
swapの領域の状況は、vmstatのswap値から大体分かります。文字通りですが。これも、ある本に書かれていた判断基準値は、以下通りになっています。
┌──────────┬─────────┐
│swap                │ 状態             │
├──────────┼─────────┤
│swap > 10000k       │問題なし          │
├──────────┼─────────┤
│4000k< swap <10000k │swap不足          │
├──────────┼─────────┤
│1000k< swap <4000k  │swap不足(危険値)  │
├──────────┼─────────┤
│swap <1000k         │swap無し(超危険)  │
└──────────┴─────────┘

●物理メモリ
物理メモリの負荷状況は、vmstatのsr値から大体分かります。sr値は、「ページデーモンがスキャンしたページ数」な訳ですから、値が大きければそれだけページデーモンが必死に活動して解放できそうなページを探しているということで、ページデーモンが必死に活動するということは、要するにメモリ不足であることが読みとれます。 で、これもある本に書かれていた判断基準値は、以下通りになっています。
┌──────────┬────────────┐
│sr                  │ 状態                   │
├──────────┼────────────┤
│0< sr <200          │問題なし                │
├──────────┼────────────┤
│200< sr <300        │物理メモリ不足          │
├──────────┼────────────┤
│1000k< swap <4000k  │swap不足(危険値)        │
├──────────┼────────────┤
│sr >300             │物理メモリ不足(危険値)  │
└──────────┴────────────┘

#---------------------------------------------------------------------------------------

dstatとは

サーバのリソース状況を確認するコマンド
中身はpythonスクリプトでコンパイル不要
vmstat や iostat などで表示される情報をまとめてカラー表示できる

dstat特徴
" 中身はpythonなのでコンパイル不要
" プラグインもある(自分で書けば好きにカスタム可能)
" 統計情報をカラー表示
" vmstatはメモリ状況やI/O状況をブロック数単位、dstatはI/O状況やネットワークの送信/受信をバイト単位で見れる


yumで
centosならyumでOK
# yum install dstat

rpm
# cd /usr/local/src
# sudo wget http://apt.sw.be/redhat/el5/en/x86_64/extras/RPMS/dstat-0.7.2-1.el5.rfx.noarch.rpm
# sudo rpm -ihv dstat-0.7.2-1.el5.rfx.noarch.rpm
# which dstat
/usr/bin/dstat 

オプションめんどいのでエイリアス追加
自分用だけにこっそり入れたかったので/home/hoge.zshrcに記述します
エイリアス追加
# vi /home/hoge.zshr
--viで追記--
if [ -x /usr/bin/dstat ]; then
   alias dstat-full='dstat -tclmdrn'
   alias dstat-mem='dstat -tclm'
   alias dstat-cpu='dstat -tclr'
   alias dstat-net='dstat -tclnd'
   alias dstat-disk='dstat -tcldr'
fi
------------
※tは時間表示ですが、T(大文字)にすることでepochになります

エイリアスで使っているオプション
オプション 説明 
t 時間表示 
T epoch time表示する 
c CPU使用率 
l ロードアベレージ 
m メモリ使用量 
r IO回数 
n ネットワークIO(単位はB/s) 
d Disk IO 
c CPU使用率 

出力結果をファイル保存
"  %outputオプションで結果をcsv保存できる
# dstat-full --output /home/hoge/dstat_`date "+%Y-%m-%d"`.csv


###############################################################################
iostatコマンドを使用したディスクI/Oの負荷状態モニタリング
###############################################################################

30秒間隔位で、データを収集すればいいと思います。一番上のデータは、システム起動時からの統計情報なので無視しましょう。この結果をファイルに保存して継続的に取得し傾向を見るのです。
# iostat -xnp 30
---
                    extended device statistics
    r/s    w/s   kr/s   kw/s wait actv wsvc_t asvc_t  %w  %b device
    0.3    1.8   12.9   10.8  0.0  0.0    0.5    1.8   0   0 c0t0d0
    0.0    0.0    0.0    0.1  0.0  0.0    1.3    2.8   0   0 c0t0d0s0
    0.0    0.0    0.0    0.2  0.0  0.0    2.5    6.7   0   0 c0t0d0s1
    0.0    0.0    0.0    0.0  0.0  0.0    0.0    0.0   0   0 c0t0d0s2
    0.0    0.1    0.0    0.6  0.0  0.0    0.5    1.6   0   0 c0t0d0s3
    0.0    0.3    0.0    0.2  0.0  0.0    0.8    1.7   0   0 c0t0d0s4
    0.0    0.0    0.9    0.1  0.0  0.0    0.4    4.2   0   0 c0t0d0s5
    0.1    0.3    1.7    1.9  0.0  0.0    0.6    3.6   0   0 c0t0d0s6
    0.2    1.1   10.2    7.8  0.0  0.0    0.4    1.2   0   0 c0t0d0s7
    0.1    2.0    2.7   20.9  0.0  0.0    1.2    2.3   0   0 c0t2d0
    0.0    0.0    0.0    0.1  0.0  0.0    3.5    5.1   0   0 c0t2d0s0
    0.0    0.0    0.2    0.0  0.0  0.0    0.4    8.2   0   0 c0t2d0s1
    0.0    0.0    0.0    0.0  0.0  0.0    0.0    0.0   0   0 c0t2d0s2
    0.0    0.1    0.0    0.6  0.0  0.0    0.9    3.2   0   0 c0t2d0s3
    0.0    0.3    0.0    0.2  0.0  0.0    2.0    3.0   0   0 c0t2d0s4
    0.0    0.0    0.9    0.1  0.0  0.0    0.5    4.4   0   0 c0t2d0s5
    0.0    0.3    0.4    3.2  0.0  0.0    1.7    4.8   0   0 c0t2d0s6
    0.0    1.2    1.3   16.7  0.0  0.0    0.8    1.2   0   0 c0t2d0s7
    0.0    0.0    0.0    0.1  0.0  0.0    6.2    9.9   0   0 d0
    0.0    0.0    0.2    0.2  0.0  0.0    0.4    9.1   0   0 d1
    0.0    0.1    0.0    0.6  0.0  0.0    4.6    5.1   0   0 d3
    0.1    0.0    1.8    0.1  0.0  0.0    0.3    5.0   0   0 d5
    0.1    0.3    2.1    3.2  0.0  0.0    2.8    7.9   0   0 d6
    0.2    1.2   11.5   16.7  0.0  0.0    0.3    2.6   0   0 d7
    0.0    0.0    0.0    0.1  0.0  0.0    0.0    4.1   0   0 d10
    0.0    0.0    0.0    0.2  0.0  0.0    0.0    9.3   0   0 d11
    0.0    0.1    0.0    0.6  0.0  0.0    0.0    2.1   0   0 d13
    0.0    0.0    0.9    0.1  0.0  0.0    0.0    4.6   0   0 d15
    0.1    0.3    1.7    1.9  0.0  0.0    0.0    4.3   0   0 d16
    0.2    1.1   10.2    7.8  0.0  0.0    0.0    1.7   0   0 d17
    0.0    0.0    0.0    0.1  0.0  0.0    0.0    8.7   0   0 d20
    0.0    0.0    0.2    0.0  0.0  0.0    0.0    8.7   0   0 d21
    0.0    0.1    0.0    0.6  0.0  0.0    0.0    4.1   0   0 d23
    0.0    0.0    0.9    0.1  0.0  0.0    0.0    4.9   0   0 d25
    0.0    0.3    0.4    3.2  0.0  0.0    0.0    6.6   0   0 d26
    0.0    1.2    1.3   16.7  0.0  0.0    0.0    2.1   0   0 d27
    0.0    0.0    0.0    0.0  0.0  0.0    0.0    0.0   0   0 c0t1d0

各値の意味は、マニュアルで調べていただくとして、これもvmstatと同様着目すべき値についてだけ記載します。 下の表は、iostatの注目すべき値とその大まかな意味を示しています。

┌──────────┬───────────────────┐
│値                  │ 意味                                 │
├──────────┼───────────────────┤
│wsvc_t              │サービス待ち行列に待機中の平均時間    │
├──────────┼───────────────────┤
│asvc_t              │アクティブになったサービスの平均時間  │
├──────────┼───────────────────┤
│svc_t               │平均サービス時間(多分wsvc_t + asvc_t) │
├──────────┼───────────────────┤
│%w                  │待ち行列が空でない時間の割合          │
├──────────┼───────────────────┤
│%b                  │ディスクがビジーである時間の割合      │
└──────────┴───────────────────┘

判断基準値をまとめると以下のようになります。

┌──────────────┬───────────────────┐
│iostatの値                  │ 状態                                 │
├──────────────┼───────────────────┤
│%w >5%                      │SCSIの過負荷                          │
├──────────────┼───────────────────┤
│30ms< svc_t <50ms && %b >20%│ディスクの過負荷                      │
├──────────────┼───────────────────┤
│svc_t >50ms && %b >20%      │ディスクの過負荷(危険値)              │
└──────────────┴───────────────────┘
ディスクI/Oが多いと、%bの値が高くなりますが、svc_tが小さければこれは単純にディスクI/Oでビジー状態になっているだけです。つまり、ディスクI/Oが多いけど、時間を掛けずに処理してるよってことですから、問題ないと判断できます。

%bに加えて、svc_tが大きくなってくると危険です。ビジー状態で尚かつ処理にも時間が掛かってるってことですから(処理に時間が掛かってるからビジーなのか？)、ディスクの過負荷によって、明らかにディスクI/Oのスループットが落ちていると言えます。

###############################################################################
netstatコマンドを使用したネットワーク状態モニタリング
###############################################################################
30秒間隔位で、データを収集すればいいと思います。一番上のデータは、システム起動時
からの統計情報なので無視しましょう。この結果をファイルに保存して継続的に取得し
傾向を見るのです。
#---------------------------------------------------------------------------------------
# netstat -i 30
---
    input   eri0      output           input  (Total)    output
packets errs  packets errs  colls  packets errs  packets errs  colls
4475176 0     8176288 78    0      5253822 0     8954934 78    0
1       0     1       0     0      1       0     1       0     0
1       0     1       0     0      1       0     1       0     0
2       0     2       0     0      2       0     2       0     0
#---------------------------------------------------------------------------------------
netstatの注目すべき値とその大まかな意味は以下の通りです。

┌──────────┬────────────┐
│値                  │意味                    │
├──────────┼────────────┤
│output packets      │送信パケット数          │
├──────────┼────────────┤
│output colls        │送信側コリジョン発生数  │
└──────────┴────────────┘
で、2.0% < 100 * (output colls) / (output packets) < 5.0%となっているとネットワ
ークが過負荷状態であると言えます。

